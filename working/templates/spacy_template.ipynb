{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "984e151005f06e7b416470b5967491b29cc1d654"
   },
   "source": [
    "Every once in a while I mess around with [spaCy](https://spacy.io/) to see what it can do. It comes with a rich set of features, including it's own pretrained language models. Some of these models include word embeddings like the ones we're given. A spaCy model might be useful here as a way to bring in additional vectors and dictionaries. Let's see what we have."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "2d3bf02b397fc92b269f76728da2706a7d7503f3"
   },
   "source": [
    "## spaCy Vectors\n",
    "\n",
    "First let's look at spaCy's \"large model\". The documentation says the model uses GloVe vectors trained on Common Crawl. We are already given the 300d vectors as a text file. I'll compare a vector from spaCy with a vector in the text file to see if there's a difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.English at 0x11aab8048>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy as sp\n",
    "\n",
    "nlp_lg = sp.load('en_core_web_lg')\n",
    "nlp_lg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "2c43e14f2d6a8156dbaba80e4356de19764af363"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 \n",
      " -0.18567,0.06601,-0.25209,-0.11725,0.26513,0.06491,0.12291,-0.09398,0.02432,2.4926 \n",
      " 300 \n",
      " -0.18567 0.06601 -0.25209 -0.11725 0.26513 0.06491 0.12291 -0.09398 0.02432 2.4926\n"
     ]
    }
   ],
   "source": [
    "# get spacy vector\n",
    "lgword = nlp_lg(\"and\")\n",
    "lgvec =   \",\".join(lgword.vector[0:10].round(5).astype(str))\n",
    "\n",
    "# get glove vector\n",
    "glv = pd.read_csv('../input/embeddings/glove.840B.300d/glove.840B.300d.txt', header=None, sep=' ', skiprows=2, nrows=5, index_col=[0])\n",
    "glvec = glv.loc['and', 0:10].round(5).astype(str).str.cat(sep=' ')\n",
    "\n",
    "print(lgword.vector.shape[0], \"\\n\",\n",
    "      lgvec, \"\\n\",\n",
    "      glv.shape[1], \"\\n\",\n",
    "      glvec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "38961fb23bd85907d8505f7f166ff47dd28d4cd1"
   },
   "source": [
    "Vectors are the same for the word \"and\" as well as other words I checked. Oh well, no new information here. \n",
    "\n",
    "Let's check the small model, which \"only includes context-sensitive tensors\". The docs say that the small models don't work as well. Maybe they can be helpful anyway as an additional source of information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_uuid": "c2ab4006b10ac04ec61fcec67c369127eb8cf2b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384 \n",
      " 0.01764,-1.59925,1.30979,-0.69968,1.02719,2.3566,1.43435,1.43921,0.0141,1.71882\n"
     ]
    }
   ],
   "source": [
    "nlp_sm = sp.load('en_core_web_sm')\n",
    "smword = nlp_sm(\"and\")\n",
    "smvec = \",\".join(smword.vector[0:10].round(5).astype(str))\n",
    "\n",
    "print(smword.vector.shape[0], \"\\n\",\n",
    "       smvec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "19e9299abfe879e11bc32206f72fd01970f3ca60"
   },
   "source": [
    "The GloVe vector and spaCy vector (or rank1 tensor if you insist) are indeed different. The model may be a useful addition to other vectors.\n",
    "\n",
    "spaCy will also calculate vectors for an entire question. The model tokenizes the string according to its own rules, gets vectors for each word, and averages them to get a single vector. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "6d36ec1ecc2d8edcdd95c2229008bf86828c03d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300,) \n",
      " [-0.15323216 -0.002314   -0.29283834 -0.26310933  0.03184     0.05062866\n",
      "  0.09317783 -0.17254166 -0.02063817  2.1729167 ]\n"
     ]
    }
   ],
   "source": [
    "e = nlp_lg('Why are aliens so smart?')\n",
    "\n",
    "print(e.vector.shape, \"\\n\",\n",
    "       e.vector[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "805af672ca42b87a21de907c982be94fecf6ed91"
   },
   "source": [
    "## Language Features\n",
    "\n",
    "spaCy has a host of other language features. You can use a built-in similarity function to compare questions. If I remember correctly, it's a shorthand function for cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "1cb7953820285c8d2cae272b0cbc708689573408"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 0.7887495576291527 0.22913418059098473\n"
     ]
    }
   ],
   "source": [
    "c = nlp_sm('What capital city is the prettiest?') \n",
    "d = nlp_sm('Which country has the nicest people?')\n",
    "e = nlp_sm('Why are aliens so smart?')\n",
    "\n",
    "print(\"\\n\", c.similarity(d),\n",
    "        c.similarity(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "abefebf801a628243ae50fb352028e329b3fbd66"
   },
   "source": [
    "The model can also lemmatize, assign parts of speech, find dependencies and otherwise annotate text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "e487911c282e39cca9a89e7cbf53b372b54f8d30"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>part of speech</th>\n",
       "      <th>stop word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Which</td>\n",
       "      <td>which</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>country</td>\n",
       "      <td>country</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>has</td>\n",
       "      <td>have</td>\n",
       "      <td>VERB</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nicest</td>\n",
       "      <td>nice</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>people</td>\n",
       "      <td>people</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      text lemmatized part of speech  stop word\n",
       "0    Which      which            ADJ      False\n",
       "1  country    country           NOUN      False\n",
       "2      has       have           VERB       True\n",
       "3      the        the            DET       True\n",
       "4   nicest       nice            ADJ      False\n",
       "5   people     people           NOUN      False\n",
       "6        ?          ?          PUNCT      False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" id=\"0\" class=\"displacy\" width=\"950\" height=\"362.0\" style=\"max-width: none; height: 362.0px; color: #000000; background: #ffffff; font-family: Arial\">\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Which</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"200\">country</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"200\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">has</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">VERB</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">the</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">DET</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">nicest</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">ADJ</tspan>\n",
       "</text>\n",
       "\n",
       "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"272.0\">\n",
       "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"800\">people?</tspan>\n",
       "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"800\">NOUN</tspan>\n",
       "</text>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-0\" stroke-width=\"2px\" d=\"M62,227.0 62,202.0 194.0,202.0 194.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-0\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M62,229.0 L58,221.0 66,221.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-1\" stroke-width=\"2px\" d=\"M212,227.0 212,202.0 344.0,202.0 344.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-1\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M212,229.0 L208,221.0 216,221.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-2\" stroke-width=\"2px\" d=\"M512,227.0 512,177.0 797.0,177.0 797.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-2\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M512,229.0 L508,221.0 516,221.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-3\" stroke-width=\"2px\" d=\"M662,227.0 662,202.0 794.0,202.0 794.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-3\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M662,229.0 L658,221.0 666,221.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "\n",
       "<g class=\"displacy-arrow\">\n",
       "    <path class=\"displacy-arc\" id=\"arrow-0-4\" stroke-width=\"2px\" d=\"M362,227.0 362,152.0 800.0,152.0 800.0,227.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
       "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
       "        <textPath xlink:href=\"#arrow-0-4\" class=\"displacy-label\" startOffset=\"50%\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
       "    </text>\n",
       "    <path class=\"displacy-arrowhead\" d=\"M800.0,229.0 L804.0,221.0 796.0,221.0\" fill=\"currentColor\"/>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"text\": [tokens.text for tokens in d], \n",
    "                   \"lemmatized\": [tokens.lemma_ for tokens in d],\n",
    "                   \"part of speech\": [tokens.pos_ for tokens in d],\n",
    "                   \"stop word\": [tokens.is_stop for tokens in d]})\n",
    "display(df)                 \n",
    "sp.displacy.render(d, style='dep', jupyter=True, options={'compact':60})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c1fba0a7b811984007e88749863e3e9b3ff5ce06"
   },
   "source": [
    "## A Simple Model\n",
    "Here's a simple model to get average vectors for each question and train a logistic regression model. The vectors are the same as the GloVe vectors we're given, except there are fewer words available. \n",
    "\n",
    "Calculating vectors for each question is time consuming. It's 4-5 times faster to get vectors for each unique token and manually average them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_kg_hide-output": false,
    "_uuid": "df68eba0141fdbc108374a5354d77ca84a55eefc",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#%% import\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy as sp\n",
    "nlp_lg = sp.load('en_core_web_lg')\n",
    "from sklearn.model_selection import StratifiedKFold, train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# get train data\n",
    "train = pd.read_csv('../input/train.csv', nrows=30_000)  #limiting the data for time's sake\n",
    "train['question_text'] = train.question_text.str.replace('?', ' ?')\n",
    "train['question_text'] = train.question_text.str.replace('.', ' .')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "e727abae8e368a1912f28016212e10b7b0038a17"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 38529/38529 [08:27<00:00, 75.85it/s]\n"
     ]
    }
   ],
   "source": [
    "tstacked = pd.DataFrame(train.question_text.str.split(expand=True).stack(), \n",
    "                columns=['token'])\n",
    "\n",
    "tlist = tstacked.token.unique().tolist()\n",
    "vlist = [nlp_lg(str).vector for str in tqdm(tlist)]\n",
    "lookup = dict(zip(tlist, vlist))\n",
    "\n",
    "tstacked['vec'] = tstacked.token.map(lookup)\n",
    "\n",
    "colnames = ['t'+str(i) for i in range(300)]\n",
    "tstacked[colnames] = pd.DataFrame(tstacked.vec.values.tolist(), \n",
    "                            index=tstacked.index)\n",
    "tstacked.drop(['token', 'vec'], axis=1, inplace=True)\n",
    "\n",
    "del tlist\n",
    "del vlist\n",
    "del lookup\n",
    "tagg = tstacked.groupby(level=0).apply(np.mean)\n",
    "del tstacked\n",
    "\n",
    "X_vecs = tagg.values\n",
    "y = train.target.values\n",
    "del tagg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "0bdc9da2d80bed6fbe9564d71e1702ccd3dd1567"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 49 epochs took 3 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    3.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 44 epochs took 3 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    3.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 49 epochs took 5 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    4.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 50 epochs took 4 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    4.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 49 epochs took 4 seconds\n",
      "finding best threshold\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    3.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.78 0.5355722492266902\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=911)\n",
    "train_pred = np.zeros(train.shape[0])\n",
    "for train_idx, val_idx in skf.split(X_vecs, y):\n",
    "    X_train, y_train  = X_vecs[train_idx], y[train_idx]\n",
    "    X_val, y_val = X_vecs[val_idx], y[val_idx]\n",
    "    model = LogisticRegression(solver='saga', class_weight='balanced', \n",
    "                                    C=0.5, max_iter=250, verbose=1, n_jobs=-1) #seed not set\n",
    "    model.fit(X_train, y_train)\n",
    "    val_pred = model.predict_proba(X_val)\n",
    "    train_pred[val_idx] = val_pred[:,1]\n",
    "    \n",
    "\n",
    "print(\"finding best threshold\")\n",
    "best_thresh = 0.0\n",
    "best_score = 0.0\n",
    "for thresh in np.arange(0, 1, 0.01):\n",
    "    score = f1_score(y, train_pred > thresh)\n",
    "    if score > best_score:\n",
    "        best_thresh = thresh\n",
    "        best_score = score\n",
    "print(best_thresh, best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_kg_hide-input": true,
    "_uuid": "8f4b687804d4cdd3314298300478b269a4194449"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.78 0.5355722492266902\n"
     ]
    }
   ],
   "source": [
    "print(best_thresh, best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "34baf05dc5548fc37604d52fb9569865da931de7"
   },
   "outputs": [],
   "source": [
    "# predict on test set\n",
    "test = pd.read_csv('../input/test.csv', index_col=['qid'])\n",
    "test.head()\n",
    "X_test = test.question_text.tolist()\n",
    "X_testvecs = np.array([nlp_lg(text).vector for text in tqdm(X_test)])\n",
    "\n",
    "trounds = 3\n",
    "preds_test = np.zeros(len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "9be6ea9d5af0751c5ebc16f755ee3e949f00306b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 44 epochs took 4 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    4.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 44 epochs took 5 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    4.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convergence after 49 epochs took 5 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   1 out of   1 | elapsed:    5.1s finished\n"
     ]
    }
   ],
   "source": [
    "for i in range(trounds):\n",
    "    model = LogisticRegression(solver='saga', class_weight='balanced', \n",
    "                                    C=0.5, max_iter=250, verbose=1, n_jobs=-1, random_state=40*i)\n",
    "    model.fit(X_vecs, y)\n",
    "    preds_test += model.predict_proba(X_testvecs)[:, 1] / trounds\n",
    "\n",
    "    \n",
    "# submit\n",
    "sub = pd.read_csv('../input/sample_submission.csv', index_col=['qid'])\n",
    "sub['prediction'] = preds_test > best_thresh\n",
    "sub.to_csv('submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "68ead7df9ae02518728ff69af90246886587a742"
   },
   "outputs": [],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "73b04ddf352de7d9e3777b6a97f61a5b0cd50699"
   },
   "source": [
    "This is a basic model trained on part of the data. So far the results have not been as good as logistic regression with tf-idf features. I think using the other annotations (parts of speech, etc.) as meta-features might be the best way to use spaCy.\n",
    "\n",
    "Alternately, you can get vectors for each word in a question and assemble them for a Keras model. See https://www.kaggle.com/enerrio/scary-nlp-with-spacy-and-keras for an example.\n",
    "\n",
    "\n",
    "\n",
    "## spaCy's CNN\n",
    "spaCy also has it's own CNN for text classification. I haven't dug into it very much, but it seems to work at a basic level. Here is an example of how to format the data and train a classifier from scratch. You can also run the code (with modifications) on a GPU for better speed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a6d7ea1b0fe2b7cae503e317d507761963459cd0"
   },
   "outputs": [],
   "source": [
    "#%% import\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy as sp\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "# get data and make json format for spacy\n",
    "train = pd.read_csv('../input/train.csv', nrows=10_000)  ## using part of the data again\n",
    "texts = train.question_text.tolist()\n",
    "cats = train.target.apply(lambda t: {'cats': {'Insincere': t == 1}}).tolist()\n",
    "train_texts, dev_texts, train_cats, dev_cats = train_test_split(texts, cats, \n",
    "        test_size=0.2, random_state=90)\n",
    "train_data = list(zip(train_texts, train_cats))\n",
    "print(\"Example format \\n\", train_data[0:10])\n",
    "\n",
    "\n",
    "#%% set up the pipeline\n",
    "nlp_bl = sp.blank('en') \n",
    "nlp_bl.vocab.vectors.name = 'spacy_pretrained_vectors'\n",
    "textcat = nlp_bl.create_pipe('textcat')\n",
    "nlp_bl.add_pipe(textcat, last=True)\n",
    "textcat.add_label('Insincere')\n",
    "\n",
    "\n",
    "# train\n",
    "n_iter = 10\n",
    "other_pipes = [pipe for pipe in nlp_bl.pipe_names if pipe != 'textcat']\n",
    "with nlp_bl.disable_pipes(*other_pipes):  #only train textcat\n",
    "    optimizer = nlp_bl.begin_training()\n",
    "    print(\"Training the model...\")\n",
    "    for i in range(n_iter):\n",
    "        losses = {}\n",
    "        batches = sp.util.minibatch(train_data, size=sp.util.compounding(4., 32., 1.001))\n",
    "        for batch in batches:\n",
    "            texts, annotations = zip(*batch)\n",
    "            nlp_bl.update(texts, annotations, sgd=optimizer, drop=0.2,\n",
    "                        losses=losses)\n",
    "        print(\"iter {} loss: {:4f}\".format(i, losses['textcat']))\n",
    "\n",
    "        \n",
    "# evaluate model\n",
    "preds = []\n",
    "docs = (nlp_bl(text) for text in dev_texts)\n",
    "for doc in docs:\n",
    "    pred = doc.cats['Insincere']\n",
    "    preds.append(pred)\n",
    "    \n",
    "truths = [val['Insincere'] for val in [dc['cats'] for dc in dev_cats]]\n",
    "\n",
    "#%% find best threshold\n",
    "best_thresh = 0.0\n",
    "best_score = 0.0\n",
    "for thresh in np.arange(0, 1, 0.01):\n",
    "    score = f1_score(truths, preds > thresh)\n",
    "    if score > best_score:\n",
    "        best_thresh = thresh\n",
    "        best_score = score\n",
    "print(best_thresh, best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e8f932dc1316e0f1be333efcdaa49d7564355cfe"
   },
   "source": [
    "Again, this model needs to run longer on more data to seee what it can do. Hope to see some clever uses of spaCy in other kernels!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c4c9a525f0b43f0c718733299bc96552ea630e2e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2b62f81ed9dbe159d2564de8cdd990c103012ab2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b216d8cc9a9bdf597dba7a94ff33cee70fe804bf"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:quora]",
   "language": "python",
   "name": "conda-env-quora-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
